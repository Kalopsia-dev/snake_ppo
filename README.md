# Proximal Policy Optimisation in Snake
OpenAI's PPO algorithm has learnt to play the all-time classic.

![Gameplay animation](https://github.com/Kalopsia-dev/snake_ppo/blob/master/assets/gameplay.gif?raw=true)

### Main Features
- A fully vectorised Snake game developed in NumPy, with an optional GUI reliant on PyGame.
- An additional wrapper class able to generate low-dimensional observation vectors for training reinforcement learning agents.
- An implementation of OpenAI's proximal policy optimisation (PPO) algorithm in PyTorch.
- Pretrained weights for an agent able to reach a highscore of 75 on a 12x9 game grid.
- A Jupyter notebook with additional information on the training environment and process.

### Requirements
- All required dependencies are listed in the included `environment.yml` file.
